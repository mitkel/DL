{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 8, 5), #60\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2), #30\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(8 * 30 * 30, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, 10)\n",
    ")\n",
    "variables = model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0        2.304 0.119\n",
      "   1        2.282 0.109\n",
      "   2        2.241 0.083\n",
      "   3        2.192 0.092\n",
      "   4        2.152 0.080\n",
      "   5        2.121 0.076\n",
      "   6        2.072 0.115\n",
      "   7        2.045 0.117\n",
      "   8        1.979 0.138\n",
      "   9        1.939 0.160\n"
     ]
    }
   ],
   "source": [
    "batch = 1000\n",
    "optimizer = torch.optim.Adam(variables)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    DATA0 = torch.empty(batch, 1, 64, 64)\n",
    "    TARGET0 = torch.empty(batch, dtype = torch.int64)\n",
    "    for sample in range(batch):\n",
    "        count = torch.randint(10, ()).item()\n",
    "        POSITIONS = torch.randint(64, (count, 2))\n",
    "        image = Image.new('L', (64, 64))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        for index in range(count):\n",
    "            draw.ellipse([tuple(POSITIONS[index] - 4), tuple(POSITIONS[index] + 4)], fill = 255)\n",
    "        DATA0[sample] = tv.transforms.functional.to_tensor(image)\n",
    "        TARGET0[sample] = count\n",
    "    \n",
    "    \n",
    "    ACTIVATION0 = model(DATA0)\n",
    "    LOSS0 = torch.nn.functional.cross_entropy(ACTIVATION0, TARGET0)\n",
    "    VALUE0 = ACTIVATION0.argmax(1)\n",
    "    ACCURACY0 = torch.eq(VALUE0, TARGET0).float().mean()\n",
    "    LOSS0.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(\"%4d %12.3f %4.3f\" % \\\n",
    "          (epoch, LOSS0, ACCURACY0), flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.,  0., 98.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., 96.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  2., 71., 23.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 27., 35.,  0., 24.,  0.,  5.,  0.],\n",
      "        [ 0.,  0.,  0., 12., 17.,  0., 38.,  0., 37., 10.],\n",
      "        [ 0.,  0.,  0.,  1.,  6.,  0., 13.,  0., 54., 22.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.,  8.,  0., 70., 26.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  2.,  0., 69., 29.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., 64., 38.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 55., 42.]])\n"
     ]
    }
   ],
   "source": [
    "CONFUSION0 = torch.zeros(10,10)\n",
    "for sample in range(batch):\n",
    "    CONFUSION0[TARGET0[sample], VALUE0[sample]] += 1\n",
    "print(CONFUSION0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
