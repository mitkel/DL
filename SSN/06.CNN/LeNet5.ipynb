{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "samples0, samples1 = 60000, 10000\n",
    "classes = 10\n",
    "\n",
    "source0 = tv.datasets.MNIST(\"../../MNIST\", train = True, download = False)\n",
    "source1 = tv.datasets.MNIST(\"../../MNIST\", train = False, download = False)\n",
    "DATA0 = source0.data.unsqueeze(1).float().cuda()\n",
    "DATA1 = source1.data.unsqueeze(1).float().cuda()\n",
    "TARGET0 = source0.targets.cuda()\n",
    "TARGET1 = source1.targets.cuda()\n",
    "\n",
    "print(DATA0[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    variables = model.parameters()\n",
    "    batch = 1000\n",
    "    optimizer = torch.optim.Adam(variables)\n",
    "    for epoch in range(100):\n",
    "        LOSS0 = torch.zeros((), device = \"cuda\")\n",
    "        ACCURACY0 = torch.zeros((), device = \"cuda\")\n",
    "        count0 = 0\n",
    "        model.train()\n",
    "        for index in range(0, samples0, batch):\n",
    "            optimizer.zero_grad()\n",
    "            DATA = DATA0[index : index + batch]\n",
    "            TARGET = TARGET0[index : index + batch]\n",
    "            count = TARGET.size(0)\n",
    "            ACTIVATION = model(DATA)\n",
    "            LOSS = torch.nn.functional.cross_entropy(ACTIVATION, TARGET)\n",
    "            LOSS0 += LOSS * count\n",
    "            VALUE = torch.argmax(ACTIVATION, 1)\n",
    "            ACCURACY0 += torch.sum(VALUE == TARGET)\n",
    "            count0 += count\n",
    "            LOSS.backward()\n",
    "            optimizer.step()\n",
    "        LOSS0 /= count0\n",
    "        ACCURACY0 /= count0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            LOSS1 = torch.zeros((), device = \"cuda\")\n",
    "            ACCURACY1 = torch.zeros((), device = \"cuda\")\n",
    "            count1 = 0\n",
    "            for index in range(0, samples1, batch):\n",
    "                DATA = DATA1[index : index + batch]\n",
    "                TARGET = TARGET1[index : index + batch]\n",
    "                ACTIVATION = model(DATA)\n",
    "                LOSS1 += torch.nn.functional.cross_entropy(ACTIVATION, TARGET, reduction = \"sum\")\n",
    "                VALUE = torch.argmax(ACTIVATION, 1)\n",
    "                ACCURACY1 += torch.sum(VALUE == TARGET)\n",
    "                count1 += TARGET.size(0)\n",
    "            LOSS1 /= count1\n",
    "            ACCURACY1 /= count1\n",
    "        print(\"%5d %12.3f %4.3f %12.3f %4.3f\" % \\\n",
    "              (epoch, LOSS0, ACCURACY0, LOSS1, ACCURACY1), flush = True)\n",
    "\n",
    "        #parameters: 46 090 + 208 = 46 298\n",
    "        #accuracy: train: 1000 test: 981\n",
    "\n",
    "        #this net with one convolutional and one dense layer performs better than two-layer dense net but has over 17 times less parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 24, 24]             208\n",
      "              ReLU-2            [-1, 8, 24, 24]               0\n",
      "         MaxPool2d-3            [-1, 8, 12, 12]               0\n",
      "       BatchNorm2d-4            [-1, 8, 12, 12]              16\n",
      "            Conv2d-5             [-1, 16, 8, 8]           3,216\n",
      "              ReLU-6             [-1, 16, 8, 8]               0\n",
      "         MaxPool2d-7             [-1, 16, 4, 4]               0\n",
      "       BatchNorm2d-8             [-1, 16, 4, 4]              32\n",
      "           Flatten-9                  [-1, 256]               0\n",
      "           Linear-10                  [-1, 128]          32,896\n",
      "             ReLU-11                  [-1, 128]               0\n",
      "           Linear-12                   [-1, 32]           4,128\n",
      "             ReLU-13                   [-1, 32]               0\n",
      "           Linear-14                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 40,826\n",
      "Trainable params: 40,826\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.11\n",
      "Params size (MB): 0.16\n",
      "Estimated Total Size (MB): 0.27\n",
      "----------------------------------------------------------------\n",
      "    0        0.808 0.795        0.138 0.961\n",
      "    1        0.112 0.968        0.076 0.977\n",
      "    2        0.075 0.978        0.057 0.982\n",
      "    3        0.058 0.983        0.049 0.984\n",
      "    4        0.048 0.986        0.043 0.986\n",
      "    5        0.041 0.988        0.039 0.987\n",
      "    6        0.035 0.989        0.037 0.988\n",
      "    7        0.031 0.991        0.035 0.989\n",
      "    8        0.027 0.993        0.033 0.989\n",
      "    9        0.023 0.994        0.032 0.989\n",
      "   10        0.021 0.995        0.031 0.990\n",
      "   11        0.018 0.995        0.031 0.989\n",
      "   12        0.016 0.996        0.031 0.989\n",
      "   13        0.014 0.997        0.031 0.989\n",
      "   14        0.013 0.997        0.033 0.989\n",
      "   15        0.011 0.998        0.035 0.989\n",
      "   16        0.010 0.998        0.037 0.988\n",
      "   17        0.009 0.998        0.039 0.988\n",
      "   18        0.008 0.998        0.034 0.989\n",
      "   19        0.007 0.999        0.032 0.990\n",
      "   20        0.006 0.999        0.035 0.989\n",
      "   21        0.006 0.999        0.039 0.989\n",
      "   22        0.006 0.999        0.037 0.988\n",
      "   23        0.006 0.999        0.036 0.989\n",
      "   24        0.005 0.999        0.035 0.990\n",
      "   25        0.005 0.999        0.044 0.988\n",
      "   26        0.004 0.999        0.051 0.987\n",
      "   27        0.004 0.999        0.048 0.987\n",
      "   28        0.005 0.999        0.046 0.988\n",
      "   29        0.005 0.999        0.043 0.989\n",
      "   30        0.006 0.998        0.044 0.988\n",
      "   31        0.006 0.998        0.043 0.990\n",
      "   32        0.006 0.998        0.043 0.988\n",
      "   33        0.005 0.998        0.047 0.989\n",
      "   34        0.005 0.998        0.055 0.988\n",
      "   35        0.005 0.998        0.047 0.989\n",
      "   36        0.003 0.999        0.049 0.989\n",
      "   37        0.003 0.999        0.045 0.990\n",
      "   38        0.002 1.000        0.043 0.990\n",
      "   39        0.001 1.000        0.042 0.991\n",
      "   40        0.001 1.000        0.042 0.990\n",
      "   41        0.001 1.000        0.041 0.991\n",
      "   42        0.000 1.000        0.042 0.991\n",
      "   43        0.000 1.000        0.040 0.991\n",
      "   44        0.000 1.000        0.041 0.991\n",
      "   45        0.000 1.000        0.041 0.991\n",
      "   46        0.000 1.000        0.041 0.991\n",
      "   47        0.000 1.000        0.041 0.991\n",
      "   48        0.000 1.000        0.041 0.991\n",
      "   49        0.000 1.000        0.041 0.991\n",
      "   50        0.000 1.000        0.041 0.991\n",
      "   51        0.000 1.000        0.042 0.991\n",
      "   52        0.000 1.000        0.042 0.991\n",
      "   53        0.000 1.000        0.042 0.991\n",
      "   54        0.000 1.000        0.042 0.991\n",
      "   55        0.000 1.000        0.042 0.991\n",
      "   56        0.000 1.000        0.042 0.991\n",
      "   57        0.000 1.000        0.043 0.991\n",
      "   58        0.000 1.000        0.043 0.991\n",
      "   59        0.000 1.000        0.043 0.991\n",
      "   60        0.000 1.000        0.043 0.991\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-96ba0ece6254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtorchsummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATA0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-3c0b6177e3dd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcount0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mDATA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATA0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mTARGET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTARGET0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 8, 5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.BatchNorm2d(8),\n",
    "    \n",
    "    torch.nn.Conv2d(8, 16, 5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.BatchNorm2d(16),\n",
    "    torch.nn.Flatten(),\n",
    "    \n",
    "    torch.nn.Linear(16*4*4, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 10)).cuda()\n",
    "\n",
    "torchsummary.summary(model1, input_size=DATA0.shape[1:])\n",
    "\n",
    "train(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 24, 24]             624\n",
      "              ReLU-2           [-1, 24, 24, 24]               0\n",
      "         MaxPool2d-3           [-1, 24, 12, 12]               0\n",
      "       BatchNorm2d-4           [-1, 24, 12, 12]              48\n",
      "            Conv2d-5             [-1, 48, 8, 8]          28,848\n",
      "              ReLU-6             [-1, 48, 8, 8]               0\n",
      "         MaxPool2d-7             [-1, 48, 4, 4]               0\n",
      "       BatchNorm2d-8             [-1, 48, 4, 4]              96\n",
      "           Flatten-9                  [-1, 768]               0\n",
      "           Linear-10                  [-1, 128]          98,432\n",
      "             ReLU-11                  [-1, 128]               0\n",
      "           Linear-12                   [-1, 32]           4,128\n",
      "             ReLU-13                   [-1, 32]               0\n",
      "           Linear-14                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 132,506\n",
      "Trainable params: 132,506\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.33\n",
      "Params size (MB): 0.51\n",
      "Estimated Total Size (MB): 0.84\n",
      "----------------------------------------------------------------\n",
      "    0        0.463 0.886        0.064 0.980\n",
      "    1        0.059 0.983        0.041 0.987\n",
      "    2        0.037 0.989        0.034 0.989\n",
      "    3        0.026 0.993        0.030 0.990\n",
      "    4        0.019 0.995        0.030 0.989\n",
      "    5        0.014 0.996        0.029 0.990\n",
      "    6        0.011 0.997        0.026 0.991\n",
      "    7        0.011 0.997        0.033 0.989\n",
      "    8        0.009 0.998        0.035 0.990\n",
      "    9        0.007 0.998        0.027 0.991\n",
      "   10        0.005 0.999        0.029 0.991\n",
      "   11        0.004 0.999        0.024 0.992\n",
      "   12        0.002 1.000        0.025 0.992\n",
      "   13        0.001 1.000        0.026 0.992\n",
      "   14        0.001 1.000        0.025 0.993\n",
      "   15        0.001 1.000        0.025 0.992\n",
      "   16        0.000 1.000        0.025 0.993\n",
      "   17        0.000 1.000        0.024 0.993\n",
      "   18        0.000 1.000        0.025 0.993\n",
      "   19        0.000 1.000        0.025 0.993\n",
      "   20        0.000 1.000        0.025 0.993\n",
      "   21        0.000 1.000        0.025 0.993\n",
      "   22        0.000 1.000        0.025 0.993\n",
      "   23        0.000 1.000        0.025 0.993\n",
      "   24        0.000 1.000        0.025 0.993\n",
      "   25        0.000 1.000        0.025 0.993\n",
      "   26        0.000 1.000        0.026 0.993\n",
      "   27        0.000 1.000        0.026 0.993\n",
      "   28        0.000 1.000        0.026 0.993\n",
      "   29        0.000 1.000        0.026 0.993\n",
      "   30        0.000 1.000        0.026 0.993\n",
      "   31        0.000 1.000        0.026 0.993\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f341bbd0a399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtorchsummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATA0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-3c0b6177e3dd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcount0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mDATA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATA0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mTARGET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTARGET0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 24, 5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.BatchNorm2d(24),\n",
    "    \n",
    "    torch.nn.Conv2d(24, 48, 5),\n",
    "    torch.nn.ReLU(),    \n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.BatchNorm2d(48),\n",
    "    torch.nn.Flatten(),\n",
    "    \n",
    "    \n",
    "    torch.nn.Linear(48*4*4, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 10)\n",
    "    ).cuda()\n",
    "\n",
    "torchsummary.summary(model2, input_size=DATA0.shape[1:])\n",
    "\n",
    "train(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 24, 24]             416\n",
      "       BatchNorm2d-2           [-1, 16, 24, 24]              32\n",
      "              ReLU-3           [-1, 16, 24, 24]               0\n",
      "            Conv2d-4           [-1, 16, 24, 24]           6,416\n",
      "              ReLU-5           [-1, 16, 24, 24]               0\n",
      "         MaxPool2d-6           [-1, 16, 12, 12]               0\n",
      "       BatchNorm2d-7           [-1, 16, 12, 12]              32\n",
      "            Conv2d-8             [-1, 16, 8, 8]           6,416\n",
      "       BatchNorm2d-9             [-1, 16, 8, 8]              32\n",
      "             ReLU-10             [-1, 16, 8, 8]               0\n",
      "           Conv2d-11             [-1, 16, 8, 8]           6,416\n",
      "             ReLU-12             [-1, 16, 8, 8]               0\n",
      "        MaxPool2d-13             [-1, 16, 4, 4]               0\n",
      "      BatchNorm2d-14             [-1, 16, 4, 4]              32\n",
      "          Flatten-15                  [-1, 256]               0\n",
      "           Linear-16                  [-1, 128]          32,896\n",
      "             ReLU-17                  [-1, 128]               0\n",
      "           Linear-18                   [-1, 32]           4,128\n",
      "             ReLU-19                   [-1, 32]               0\n",
      "           Linear-20                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 57,146\n",
      "Trainable params: 57,146\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.43\n",
      "Params size (MB): 0.22\n",
      "Estimated Total Size (MB): 0.66\n",
      "----------------------------------------------------------------\n",
      "    0        0.680 0.838        0.079 0.974\n",
      "    1        0.064 0.981        0.044 0.986\n",
      "    2        0.042 0.988        0.033 0.989\n",
      "    3        0.031 0.991        0.030 0.989\n",
      "    4        0.024 0.993        0.032 0.988\n",
      "    5        0.019 0.994        0.036 0.987\n",
      "    6        0.015 0.996        0.034 0.988\n",
      "    7        0.013 0.997        0.029 0.991\n",
      "    8        0.014 0.996        0.028 0.990\n",
      "    9        0.011 0.997        0.030 0.991\n",
      "   10        0.010 0.997        0.028 0.992\n",
      "   11        0.008 0.998        0.028 0.991\n",
      "   12        0.006 0.998        0.030 0.992\n",
      "   13        0.005 0.999        0.030 0.991\n",
      "   14        0.004 0.999        0.029 0.992\n",
      "   15        0.003 0.999        0.026 0.992\n",
      "   16        0.002 1.000        0.027 0.993\n",
      "   17        0.001 1.000        0.030 0.992\n",
      "   18        0.001 1.000        0.032 0.992\n",
      "   19        0.001 1.000        0.033 0.992\n",
      "   20        0.001 1.000        0.028 0.993\n",
      "   21        0.001 1.000        0.030 0.993\n",
      "   22        0.001 1.000        0.032 0.993\n",
      "   23        0.001 1.000        0.029 0.993\n",
      "   24        0.001 1.000        0.028 0.994\n",
      "   25        0.001 1.000        0.031 0.993\n",
      "   26        0.000 1.000        0.027 0.993\n",
      "   27        0.000 1.000        0.033 0.992\n",
      "   28        0.002 0.999        0.038 0.991\n",
      "   29        0.011 0.997        0.038 0.989\n",
      "   30        0.015 0.995        0.036 0.989\n",
      "   31        0.009 0.997        0.033 0.992\n",
      "   32        0.004 0.999        0.030 0.992\n",
      "   33        0.002 1.000        0.030 0.993\n",
      "   34        0.001 1.000        0.026 0.993\n",
      "   35        0.000 1.000        0.024 0.993\n",
      "   36        0.000 1.000        0.024 0.994\n",
      "   37        0.000 1.000        0.025 0.994\n",
      "   38        0.000 1.000        0.026 0.994\n",
      "   39        0.000 1.000        0.026 0.994\n",
      "   40        0.000 1.000        0.026 0.994\n",
      "   41        0.000 1.000        0.026 0.994\n",
      "   42        0.000 1.000        0.026 0.994\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-643d2abb5f96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtorchsummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATA0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-3c0b6177e3dd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mcount0\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mLOSS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mLOSS0\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mcount0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mACCURACY0\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mcount0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model3 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 16, 5),\n",
    "    torch.nn.BatchNorm2d(16),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 16, 5, padding=2),\n",
    "    torch.nn.ReLU(),    \n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.BatchNorm2d(16),\n",
    "    \n",
    "    \n",
    "    torch.nn.Conv2d(16, 16, 5),\n",
    "    torch.nn.BatchNorm2d(16),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 16, 5, padding=2),\n",
    "    torch.nn.ReLU(),    \n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.BatchNorm2d(16),\n",
    "    torch.nn.Flatten(),\n",
    "    \n",
    "    torch.nn.Linear(16*4*4, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 10)\n",
    "    ).cuda()\n",
    "\n",
    "torchsummary.summary(model3, input_size=DATA0.shape[1:])\n",
    "train(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 24, 24]             832\n",
      "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
      "              ReLU-3           [-1, 32, 24, 24]               0\n",
      "            Conv2d-4           [-1, 32, 24, 24]          25,632\n",
      "              ReLU-5           [-1, 32, 24, 24]               0\n",
      "         MaxPool2d-6           [-1, 32, 12, 12]               0\n",
      "       BatchNorm2d-7           [-1, 32, 12, 12]              64\n",
      "           Dropout-8           [-1, 32, 12, 12]               0\n",
      "            Conv2d-9             [-1, 64, 8, 8]          51,264\n",
      "      BatchNorm2d-10             [-1, 64, 8, 8]             128\n",
      "             ReLU-11             [-1, 64, 8, 8]               0\n",
      "           Conv2d-12             [-1, 64, 8, 8]         102,464\n",
      "             ReLU-13             [-1, 64, 8, 8]               0\n",
      "        MaxPool2d-14             [-1, 64, 4, 4]               0\n",
      "      BatchNorm2d-15             [-1, 64, 4, 4]             128\n",
      "          Flatten-16                 [-1, 1024]               0\n",
      "          Dropout-17                 [-1, 1024]               0\n",
      "           Linear-18                  [-1, 128]         131,200\n",
      "             ReLU-19                  [-1, 128]               0\n",
      "          Dropout-20                  [-1, 128]               0\n",
      "           Linear-21                   [-1, 32]           4,128\n",
      "             ReLU-22                   [-1, 32]               0\n",
      "           Linear-23                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 316,234\n",
      "Trainable params: 316,234\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.00\n",
      "Params size (MB): 1.21\n",
      "Estimated Total Size (MB): 2.21\n",
      "----------------------------------------------------------------\n",
      "    0        0.410 0.884        0.052 0.984\n",
      "    1        0.056 0.983        0.035 0.988\n",
      "    2        0.037 0.989        0.027 0.990\n",
      "    3        0.030 0.991        0.020 0.994\n",
      "    4        0.025 0.992        0.024 0.992\n",
      "    5        0.022 0.993        0.021 0.993\n",
      "    6        0.021 0.993        0.023 0.992\n",
      "    7        0.019 0.994        0.019 0.994\n",
      "    8        0.016 0.995        0.019 0.995\n",
      "    9        0.015 0.995        0.018 0.994\n",
      "   10        0.013 0.996        0.022 0.993\n",
      "   11        0.012 0.996        0.018 0.995\n",
      "   12        0.012 0.996        0.017 0.995\n",
      "   13        0.010 0.997        0.017 0.995\n",
      "   14        0.010 0.997        0.020 0.994\n",
      "   15        0.010 0.997        0.021 0.994\n",
      "   16        0.009 0.997        0.015 0.996\n",
      "   17        0.008 0.997        0.017 0.995\n",
      "   18        0.008 0.997        0.019 0.995\n",
      "   19        0.008 0.998        0.023 0.994\n",
      "   20        0.008 0.997        0.018 0.995\n",
      "   21        0.006 0.998        0.020 0.994\n",
      "   22        0.006 0.998        0.020 0.995\n",
      "   23        0.006 0.998        0.016 0.996\n",
      "   24        0.006 0.998        0.020 0.994\n",
      "   25        0.006 0.998        0.025 0.993\n",
      "   26        0.005 0.998        0.017 0.996\n",
      "   27        0.005 0.998        0.021 0.994\n",
      "   28        0.005 0.998        0.017 0.994\n",
      "   29        0.006 0.998        0.018 0.995\n",
      "   30        0.006 0.998        0.019 0.995\n",
      "   31        0.005 0.998        0.024 0.995\n",
      "   32        0.006 0.998        0.021 0.995\n",
      "   33        0.005 0.998        0.021 0.995\n",
      "   34        0.005 0.998        0.031 0.993\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-19eda44e9d0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mtorchsummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATA0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-47b5faef8a15>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mACCURACY0\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVALUE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTARGET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mcount0\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mLOSS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mLOSS0\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mcount0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model4 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 32, 5),\n",
    "    torch.nn.BatchNorm2d(32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(32, 32, 5, padding=2),\n",
    "    torch.nn.ReLU(),    \n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.BatchNorm2d(32),\n",
    "    \n",
    "    torch.nn.Dropout(0.3),\n",
    "    \n",
    "    torch.nn.Conv2d(32, 64, 5),\n",
    "    torch.nn.BatchNorm2d(64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(64, 64, 5, padding=2),\n",
    "    torch.nn.ReLU(),    \n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.BatchNorm2d(64),\n",
    "    torch.nn.Flatten(),\n",
    "    \n",
    "    torch.nn.Dropout(0.3),\n",
    "    \n",
    "    torch.nn.Linear(64*4*4, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.3),\n",
    "    \n",
    "    torch.nn.Linear(128, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 10)\n",
    "    ).cuda()\n",
    "\n",
    "torchsummary.summary(model4, input_size=DATA0.shape[1:])\n",
    "train(model4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
