{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = datasets.load_digits()\n",
    "data0 = source.data\n",
    "target0 = source.target\n",
    "design0 = np.insert(data, 0, 1., 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0       18.813 0.530\n",
      "    1        5.167 0.856\n",
      "    2        0.678 0.934\n",
      "    3        0.568 0.940\n",
      "    4        0.519 0.944\n",
      "    5        0.420 0.952\n",
      "    6        0.528 0.946\n",
      "    7        0.295 0.959\n",
      "    8        0.289 0.957\n",
      "    9        0.241 0.959\n",
      "   10        0.274 0.958\n",
      "   11        0.339 0.962\n",
      "   12        0.171 0.967\n",
      "   13        0.166 0.971\n",
      "   14        0.187 0.968\n",
      "   15        0.134 0.974\n",
      "   16        0.128 0.976\n",
      "   17        0.104 0.974\n",
      "   18        0.103 0.978\n",
      "   19        0.091 0.979\n",
      "   20        0.073 0.984\n",
      "   21        0.064 0.985\n",
      "   22        0.054 0.988\n",
      "   23        0.055 0.987\n",
      "   24        0.054 0.984\n",
      "   25        0.039 0.989\n",
      "   26        0.056 0.988\n",
      "   27        0.026 0.993\n",
      "   28        0.029 0.991\n",
      "   29        0.034 0.989\n",
      "   30        0.022 0.996\n",
      "   31        0.021 0.997\n",
      "   32        0.016 0.997\n",
      "   33        0.014 0.998\n",
      "   34        0.014 0.996\n",
      "   35        0.011 0.999\n",
      "   36        0.010 0.999\n",
      "   37        0.009 0.999\n",
      "   38        0.008 0.999\n",
      "   39        0.007 0.999\n",
      "   40        0.006 0.999\n",
      "   41        0.006 0.999\n",
      "   42        0.005 0.999\n",
      "   43        0.005 0.999\n",
      "   44        0.005 0.999\n",
      "   45        0.004 1.000\n",
      "   46        0.004 1.000\n",
      "   47        0.004 1.000\n",
      "   48        0.003 1.000\n",
      "   49        0.003 1.000\n",
      "   50        0.003 1.000\n",
      "   51        0.003 1.000\n",
      "   52        0.003 1.000\n",
      "   53        0.002 1.000\n",
      "   54        0.002 1.000\n",
      "   55        0.002 1.000\n",
      "   56        0.002 1.000\n",
      "   57        0.002 1.000\n",
      "   58        0.002 1.000\n",
      "   59        0.002 1.000\n",
      "   60        0.002 1.000\n",
      "   61        0.002 1.000\n",
      "   62        0.002 1.000\n",
      "   63        0.002 1.000\n",
      "   64        0.002 1.000\n",
      "   65        0.002 1.000\n",
      "   66        0.002 1.000\n",
      "   67        0.002 1.000\n",
      "   68        0.001 1.000\n",
      "   69        0.001 1.000\n",
      "   70        0.001 1.000\n",
      "   71        0.001 1.000\n",
      "   72        0.001 1.000\n",
      "   73        0.001 1.000\n",
      "   74        0.001 1.000\n",
      "   75        0.001 1.000\n",
      "   76        0.001 1.000\n",
      "   77        0.001 1.000\n",
      "   78        0.001 1.000\n",
      "   79        0.001 1.000\n",
      "   80        0.001 1.000\n",
      "   81        0.001 1.000\n",
      "   82        0.001 1.000\n",
      "   83        0.001 1.000\n",
      "   84        0.001 1.000\n",
      "   85        0.001 1.000\n",
      "   86        0.001 1.000\n",
      "   87        0.001 1.000\n",
      "   88        0.001 1.000\n",
      "   89        0.001 1.000\n",
      "   90        0.001 1.000\n",
      "   91        0.001 1.000\n",
      "   92        0.001 1.000\n",
      "   93        0.001 1.000\n",
      "   94        0.001 1.000\n",
      "   95        0.001 1.000\n",
      "   96        0.001 1.000\n",
      "   97        0.001 1.000\n",
      "   98        0.001 1.000\n",
      "   99        0.001 1.000\n"
     ]
    }
   ],
   "source": [
    "features = 64\n",
    "classes = 10\n",
    "samples = 1797\n",
    "\n",
    "\n",
    "DESIGN0 = torch.tensor(design0, dtype = torch.float32)\n",
    "TARGET0 = torch.tensor(target0, dtype = torch.int64)\n",
    "\n",
    "PARAM = torch.zeros(1+ features, classes, requires_grad = True)\n",
    "batch = 64\n",
    "opt = torch.optim.SGD([PARAM], lr = 0.1)\n",
    "\n",
    "for epoch in range(100):\n",
    "    # empty bracket so that this tensor contains a number\n",
    "    LOSS0 = torch.zeros(())\n",
    "    ACC0 = torch.zeros(())\n",
    "    count0 = 0\n",
    "    \n",
    "    for index in range(0, samples, batch):\n",
    "        opt.zero_grad()\n",
    "        DESIGN = DESIGN0[index : index + batch]\n",
    "        TARGET = TARGET0[index : index + batch]\n",
    "        count = TARGET.size(0)\n",
    "        \n",
    "        ACTIVATION = DESIGN @ PARAM\n",
    "        LOSS = torch.nn.functional.cross_entropy(ACTIVATION, TARGET)\n",
    "        LOSS0 += LOSS*count\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            VALUE = torch.argmax( ACTIVATION, 1)\n",
    "            ACC0 += torch.sum(VALUE == TARGET)\n",
    "            count0 += count\n",
    "        \n",
    "        LOSS.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    LOSS0 /= count0\n",
    "    ACC0 /= count0\n",
    "    print(\"%5d %12.3f %4.3f\" % (epoch, LOSS0, ACC0), flush = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
