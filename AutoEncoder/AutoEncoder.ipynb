{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder\n",
    "Refs: [DL book](https://www.deeplearningbook.org/contents/autoencoders.html); [inspired by](https://gist.github.com/AFAgarap/4f8a8d8edf352271fa06d85ba0361f26).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch       \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import special_ortho_group\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.693 -0.721]\n",
      " [ 0.721 -0.693]] tensor([0.442, 1.298]) tensor([ 0.629, -1.218])\n",
      "tensor([[ 0.195, -0.151, -0.151,  ...,  0.066,  0.088,  0.031],\n",
      "        [-1.100,  1.286,  0.979,  ..., -0.452, -1.255,  0.434],\n",
      "        [-0.335, -0.075,  0.163,  ..., -0.051,  0.438, -0.525],\n",
      "        ...,\n",
      "        [-0.364,  0.319,  0.293,  ..., -0.130, -0.227, -0.007],\n",
      "        [ 0.278, -0.574, -0.320,  ...,  0.161,  0.754, -0.460],\n",
      "        [ 1.233, -0.439, -0.808,  ...,  0.320, -0.353,  0.925]])\n",
      "tensor([[ 0.539, -0.808,  0.757,  ..., -0.521, -1.217, -1.289],\n",
      "        [-0.663,  0.374, -1.268,  ...,  0.784,  0.302, -0.795],\n",
      "        [ 1.319, -1.233, -0.917,  ...,  0.871, -0.016, -0.044],\n",
      "        ...,\n",
      "        [ 0.801,  0.157,  0.312,  ...,  0.545, -0.049, -0.144],\n",
      "        [ 1.947, -0.444,  1.982,  ..., -0.452, -0.150,  1.633],\n",
      "        [ 0.113,  0.215,  0.956,  ..., -0.076,  0.047, -0.731]])\n"
     ]
    }
   ],
   "source": [
    "x = special_ortho_group.rvs(2)\n",
    "z = torch.randn(2)\n",
    "print( x, z, (z @ x).float())\n",
    "v, _  = gen_data(**{**params, \"true_dim\":2})\n",
    "print(v)\n",
    "print(data0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture\n",
    "class shallow_AE(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder_layer = nn.Linear(\n",
    "            in_features=kwargs[\"input_width\"], out_features=kwargs[\"hidden_width\"], bias=kwargs[\"bias\"]\n",
    "        )\n",
    "        self.decoder_layer = nn.Linear(\n",
    "            in_features=kwargs[\"hidden_width\"], out_features=kwargs[\"input_width\"], bias=kwargs[\"bias\"]\n",
    "        )\n",
    "        \n",
    "        if 'linear' in kwargs:\n",
    "            self.linear = kwargs['linear']\n",
    "        else:\n",
    "            self.linear = False\n",
    "\n",
    "    def forward(self, features):\n",
    "        activation = self.encoder_layer(features)\n",
    "        if not self.linear:\n",
    "            activation = F.relu(activation)\n",
    "        reconstructed = self.decoder_layer(activation)\n",
    "        return reconstructed\n",
    "    \n",
    "def train(model, epochs, train_loader, optimizer, criterion, verbose=True):\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        for batch_features in train_loader:\n",
    "            batch_features = batch_features.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(batch_features)\n",
    "            train_loss = criterion(outputs, batch_features)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            loss += train_loss.item()\n",
    "\n",
    "        loss = loss / len(train_loader)\n",
    "        if verbose:\n",
    "            print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))\n",
    "    if verbose:\n",
    "        print(\"===================\\n\")\n",
    "    return model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(**kwargs):\n",
    "    data0 = torch.randn(kwargs['samples'], kwargs['input_width'])\n",
    "    \n",
    "    if ('true_dim' in kwargs) and (kwargs['true_dim']<kwargs['input_width']):\n",
    "        data0[:,kwargs['true_dim']:] = 0\n",
    "        data0 = data0 @ special_ortho_group.rvs(kwargs['input_width'])\n",
    "        data0 = data0.float()\n",
    "        \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        data0, batch_size=kwargs['batch_size']\n",
    "    )\n",
    "    \n",
    "    return data0, train_loader\n",
    "\n",
    "def PCA_compare(model, model_loss, data0, **kwargs):\n",
    "    U, s, V = np.linalg.svd(data0, full_matrices=False)\n",
    "\n",
    "    b=np.append(s[:kwargs['hidden_width']], np.zeros(len(s)-kwargs['hidden_width']))\n",
    "    L_opt = np.sum(s**2-b**2)*kwargs['batch_size']/kwargs['samples']\n",
    "\n",
    "    print(\"Model loss = \", model_loss)\n",
    "    print(\"PCA loss = \", L_opt)\n",
    "\n",
    "#     print(\"\\nModel params:\")\n",
    "#     for n, p in model.named_parameters():\n",
    "#         print(n, p)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"model estimate:\\n\", model(data0.to(device)).detach().cpu().numpy())\n",
    "        print(\"\\nPCA estimate:\\n\", U  @ np.diag(b) @ V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear activation implies that AutoEncoder = PCA\n",
    "\n",
    "### Underparametrization: hidden_width < true_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss =  192.28164459228515\n",
      "PCA loss =  191.9860397593492\n",
      "model estimate:\n",
      " [[ 0.216 -0.64   0.301 ... -1.359  0.21   0.481]\n",
      " [-0.151 -0.795  1.515 ... -0.082 -0.028  0.253]\n",
      " [-0.549 -0.317 -1.435 ... -0.015 -0.863  0.082]\n",
      " ...\n",
      " [-0.211  0.336  0.712 ...  1.422 -0.085 -0.402]\n",
      " [ 0.096  0.005 -1.608 ... -1.101 -0.139  0.229]\n",
      " [-0.233 -1.06   0.029 ... -1.133 -0.376  0.547]]\n",
      "\n",
      "PCA estimate:\n",
      " [[ 0.217 -0.672  0.312 ... -1.35   0.198  0.482]\n",
      " [-0.134 -0.807  1.513 ... -0.068 -0.035  0.257]\n",
      " [-0.558 -0.319 -1.431 ... -0.033 -0.871  0.098]\n",
      " ...\n",
      " [-0.206  0.347  0.709 ...  1.41  -0.079 -0.396]\n",
      " [ 0.092  0.029 -1.619 ... -1.092 -0.131  0.216]\n",
      " [-0.222 -1.081  0.036 ... -1.134 -0.384  0.558]]\n"
     ]
    }
   ],
   "source": [
    "# hyperparams\n",
    "params = {\n",
    "    # data    \n",
    "    \"input_width\": 10, \n",
    "    \"samples\": 10000,\n",
    "    \"true_dim\":5,\n",
    "    \n",
    "    # model\n",
    "    \"hidden_width\":3,\n",
    "    \"linear\":True,\n",
    "    \"bias\": False,\n",
    "    \n",
    "    # training\n",
    "    \"lr\": 1e-3,\n",
    "    \"batch_size\": 100,\n",
    "    \"epochs\": 100\n",
    "}\n",
    "\n",
    "data0, train_loader = gen_data(**params)\n",
    "\n",
    "model = shallow_AE(**params).to(device)\n",
    "opt = optim.SGD(model.parameters(), lr=params['lr'])\n",
    "crit = nn.MSELoss(reduction='sum')\n",
    "\n",
    "model_trained, model_loss = train(model, params[\"epochs\"], train_loader, opt, crit, verbose=False)\n",
    "\n",
    "PCA_compare(model_trained, model_loss, data0, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is ReLU better than linear network = PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/100, loss = 504.310846\n",
      "epoch : 2/100, loss = 457.270787\n",
      "epoch : 3/100, loss = 427.894512\n",
      "epoch : 4/100, loss = 402.553207\n",
      "epoch : 5/100, loss = 374.410618\n",
      "epoch : 6/100, loss = 349.275901\n",
      "epoch : 7/100, loss = 333.778637\n",
      "epoch : 8/100, loss = 325.870995\n",
      "epoch : 9/100, loss = 322.070581\n",
      "epoch : 10/100, loss = 320.252884\n",
      "epoch : 11/100, loss = 319.393210\n",
      "epoch : 12/100, loss = 318.987177\n",
      "epoch : 13/100, loss = 318.778345\n",
      "epoch : 14/100, loss = 318.651924\n",
      "epoch : 15/100, loss = 318.553513\n",
      "epoch : 16/100, loss = 318.476890\n",
      "epoch : 17/100, loss = 318.409689\n",
      "epoch : 18/100, loss = 318.342097\n",
      "epoch : 19/100, loss = 318.267109\n",
      "epoch : 20/100, loss = 318.195985\n",
      "epoch : 21/100, loss = 318.118884\n",
      "epoch : 22/100, loss = 318.045275\n",
      "epoch : 23/100, loss = 317.968670\n",
      "epoch : 24/100, loss = 317.895292\n",
      "epoch : 25/100, loss = 317.821827\n",
      "epoch : 26/100, loss = 317.754227\n",
      "epoch : 27/100, loss = 317.685171\n",
      "epoch : 28/100, loss = 317.613226\n",
      "epoch : 29/100, loss = 317.545508\n",
      "epoch : 30/100, loss = 317.485646\n",
      "epoch : 31/100, loss = 317.428653\n",
      "epoch : 32/100, loss = 317.376293\n",
      "epoch : 33/100, loss = 317.328848\n",
      "epoch : 34/100, loss = 317.289291\n",
      "epoch : 35/100, loss = 317.253458\n",
      "epoch : 36/100, loss = 317.226527\n",
      "epoch : 37/100, loss = 317.203141\n",
      "epoch : 38/100, loss = 317.179188\n",
      "epoch : 39/100, loss = 317.157061\n",
      "epoch : 40/100, loss = 317.132839\n",
      "epoch : 41/100, loss = 317.106331\n",
      "epoch : 42/100, loss = 317.087057\n",
      "epoch : 43/100, loss = 317.067686\n",
      "epoch : 44/100, loss = 317.049925\n",
      "epoch : 45/100, loss = 317.032990\n",
      "epoch : 46/100, loss = 317.016783\n",
      "epoch : 47/100, loss = 316.995715\n",
      "epoch : 48/100, loss = 316.979516\n",
      "epoch : 49/100, loss = 316.964529\n",
      "epoch : 50/100, loss = 316.947817\n",
      "epoch : 51/100, loss = 316.932616\n",
      "epoch : 52/100, loss = 316.918109\n",
      "epoch : 53/100, loss = 316.903624\n",
      "epoch : 54/100, loss = 316.888808\n",
      "epoch : 55/100, loss = 316.878956\n",
      "epoch : 56/100, loss = 316.866668\n",
      "epoch : 57/100, loss = 316.855815\n",
      "epoch : 58/100, loss = 316.848126\n",
      "epoch : 59/100, loss = 316.840628\n",
      "epoch : 60/100, loss = 316.834634\n",
      "epoch : 61/100, loss = 316.829931\n",
      "epoch : 62/100, loss = 316.825237\n",
      "epoch : 63/100, loss = 316.822280\n",
      "epoch : 64/100, loss = 316.818152\n",
      "epoch : 65/100, loss = 316.811195\n",
      "epoch : 66/100, loss = 316.805830\n",
      "epoch : 67/100, loss = 316.800360\n",
      "epoch : 68/100, loss = 316.793593\n",
      "epoch : 69/100, loss = 316.787862\n",
      "epoch : 70/100, loss = 316.780391\n",
      "epoch : 71/100, loss = 316.776721\n",
      "epoch : 72/100, loss = 316.771682\n",
      "epoch : 73/100, loss = 316.766301\n",
      "epoch : 74/100, loss = 316.761051\n",
      "epoch : 75/100, loss = 316.757461\n",
      "epoch : 76/100, loss = 316.752875\n",
      "epoch : 77/100, loss = 316.746262\n",
      "epoch : 78/100, loss = 316.738952\n",
      "epoch : 79/100, loss = 316.730833\n",
      "epoch : 80/100, loss = 316.721825\n",
      "epoch : 81/100, loss = 316.715198\n",
      "epoch : 82/100, loss = 316.709809\n",
      "epoch : 83/100, loss = 316.706566\n",
      "epoch : 84/100, loss = 316.703706\n",
      "epoch : 85/100, loss = 316.700912\n",
      "epoch : 86/100, loss = 316.698532\n",
      "epoch : 87/100, loss = 316.696530\n",
      "epoch : 88/100, loss = 316.693221\n",
      "epoch : 89/100, loss = 316.691348\n",
      "epoch : 90/100, loss = 316.689942\n",
      "epoch : 91/100, loss = 316.687219\n",
      "epoch : 92/100, loss = 316.687089\n",
      "epoch : 93/100, loss = 316.684689\n",
      "epoch : 94/100, loss = 316.683310\n",
      "epoch : 95/100, loss = 316.682080\n",
      "epoch : 96/100, loss = 316.680779\n",
      "epoch : 97/100, loss = 316.678238\n",
      "epoch : 98/100, loss = 316.676794\n",
      "epoch : 99/100, loss = 316.673510\n",
      "epoch : 100/100, loss = 316.672731\n",
      "===================\n",
      "\n",
      "Model loss =  316.6727307128906\n",
      "PCA loss =  191.9860397593492\n",
      "model estimate:\n",
      " [[-0.217 -0.397 -0.304 ... -1.033 -0.059  0.251]\n",
      " [-0.58  -0.802  1.197 ...  0.306 -0.26  -0.054]\n",
      " [ 0.     0.     0.    ...  0.     0.     0.   ]\n",
      " ...\n",
      " [-0.371 -0.474  1.363 ...  0.782 -0.09  -0.217]\n",
      " [-0.348 -0.589 -0.408 ... -1.215 -0.204  0.342]\n",
      " [-0.524 -0.812 -0.491 ... -1.144 -0.477  0.419]]\n",
      "\n",
      "PCA estimate:\n",
      " [[ 0.217 -0.672  0.312 ... -1.35   0.198  0.482]\n",
      " [-0.134 -0.807  1.513 ... -0.068 -0.035  0.257]\n",
      " [-0.558 -0.319 -1.431 ... -0.033 -0.871  0.098]\n",
      " ...\n",
      " [-0.206  0.347  0.709 ...  1.41  -0.079 -0.396]\n",
      " [ 0.092  0.029 -1.619 ... -1.092 -0.131  0.216]\n",
      " [-0.222 -1.081  0.036 ... -1.134 -0.384  0.558]]\n"
     ]
    }
   ],
   "source": [
    "params[\"linear\"] = False\n",
    "\n",
    "\n",
    "model = shallow_AE(**params).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "crit = nn.MSELoss(reduction='sum')\n",
    "\n",
    "model_trained, model_loss = train(model, params[\"epochs\"], train_loader, opt, crit, verbose=True)\n",
    "\n",
    "PCA_compare(model_trained, model_loss, data0, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overparametrization: hidden_width > true_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss =  3.606985374444982e-12\n",
      "PCA loss =  -5.792436355976684e-06\n",
      "model estimate:\n",
      " [[-0.581 -0.242 -0.506 ... -0.126  0.448 -0.004]\n",
      " [-0.248  0.156  0.158 ...  0.11   0.102 -0.025]\n",
      " [ 0.076 -0.252 -0.344 ... -0.164  0.039  0.026]\n",
      " ...\n",
      " [-0.235 -0.476 -0.751 ... -0.291  0.312  0.032]\n",
      " [-0.484  0.561  0.681 ...  0.379  0.11  -0.07 ]\n",
      " [-0.104 -0.073 -0.134 ... -0.041  0.091  0.002]]\n",
      "\n",
      "PCA estimate:\n",
      " [[-0.581 -0.242 -0.506 ... -0.126  0.448 -0.004]\n",
      " [-0.248  0.156  0.158 ...  0.11   0.102 -0.025]\n",
      " [ 0.076 -0.252 -0.344 ... -0.164  0.039  0.026]\n",
      " ...\n",
      " [-0.235 -0.476 -0.751 ... -0.291  0.312  0.032]\n",
      " [-0.484  0.561  0.681 ...  0.379  0.11  -0.07 ]\n",
      " [-0.104 -0.073 -0.134 ... -0.041  0.091  0.002]]\n"
     ]
    }
   ],
   "source": [
    "params['true_dim'] = params['hidden_width']-1\n",
    "params['linear'] = True\n",
    "\n",
    "data0, train_loader = gen_data(**params)\n",
    "\n",
    "model = shallow_AE(**params).to(device)\n",
    "opt = optim.SGD(model.parameters(), lr=params['lr'])\n",
    "crit = nn.MSELoss(reduction='sum')\n",
    "\n",
    "model_trained, model_loss = train(model, params[\"epochs\"], train_loader, opt, crit, verbose=False)\n",
    "\n",
    "model_loss\n",
    "PCA_compare(model_trained, model_loss, data0, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss =  31.719064273834228\n",
      "PCA loss =  -4.535846459888372e-06\n",
      "model estimate:\n",
      " [[-0.242 -0.687 -1.209 ... -0.358 -0.776  0.467]\n",
      " [ 0.472  1.358  0.309 ...  0.394 -0.017  0.809]\n",
      " [ 0.09   0.263 -0.352 ...  0.014 -0.31   0.499]\n",
      " ...\n",
      " [-0.277 -0.785 -1.381 ... -0.409 -0.886  0.533]\n",
      " [ 0.326  0.939  0.214 ...  0.272 -0.012  0.559]\n",
      " [ 0.003  0.005  0.392 ...  0.061  0.291 -0.322]]\n",
      "\n",
      "PCA estimate:\n",
      " [[-0.092 -0.254 -1.217 ... -0.249 -0.861  0.814]\n",
      " [ 0.425  1.22   0.442 ...  0.379  0.107  0.589]\n",
      " [ 0.117  0.344 -0.641 ... -0.008 -0.54   0.803]\n",
      " ...\n",
      " [-0.397 -1.133 -1.078 ... -0.452 -0.596  0.008]\n",
      " [ 0.271  0.783 -0.065 ...  0.19  -0.192  0.669]\n",
      " [ 0.095  0.266  0.681 ...  0.171  0.459 -0.358]]\n"
     ]
    }
   ],
   "source": [
    "params['linear'] = False\n",
    "\n",
    "data0, train_loader = gen_data(**params)\n",
    "\n",
    "model = shallow_AE(**params).to(device)\n",
    "opt = optim.SGD(model.parameters(), lr=params['lr'])\n",
    "crit = nn.MSELoss(reduction='sum')\n",
    "\n",
    "model_trained, model_loss = train(model, params[\"epochs\"], train_loader, opt, crit, verbose=False)\n",
    "\n",
    "model_loss\n",
    "PCA_compare(model_trained, model_loss, data0, **params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
