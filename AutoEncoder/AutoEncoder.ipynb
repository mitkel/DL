{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder\n",
    "Refs: [DL book](https://www.deeplearningbook.org/contents/autoencoders.html); [inspired by](https://gist.github.com/AFAgarap/4f8a8d8edf352271fa06d85ba0361f26).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch       \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import special_ortho_group\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture\n",
    "class shallow_AE(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder_layer = nn.Linear(\n",
    "            in_features=kwargs[\"input_width\"], out_features=kwargs[\"hidden_width\"], bias=kwargs[\"bias\"]\n",
    "        )\n",
    "        self.decoder_layer = nn.Linear(\n",
    "            in_features=kwargs[\"hidden_width\"], out_features=kwargs[\"input_width\"], bias=kwargs[\"bias\"]\n",
    "        )\n",
    "        \n",
    "        if 'linear' in kwargs:\n",
    "            self.linear = kwargs['linear']\n",
    "        else:\n",
    "            self.linear = False\n",
    "\n",
    "    def forward(self, features):\n",
    "        activation = self.encoder_layer(features)\n",
    "        if not self.linear:\n",
    "            activation = F.relu(activation)\n",
    "        reconstructed = self.decoder_layer(activation)\n",
    "        return reconstructed\n",
    "    \n",
    "def train(model, epochs, train_loader, optimizer, criterion, verbose=True):\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        for batch_features in train_loader:\n",
    "            batch_features = batch_features.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(batch_features)\n",
    "            train_loss = criterion(outputs, batch_features)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            loss += train_loss.item()\n",
    "\n",
    "        loss = loss / len(train_loader)\n",
    "        if verbose:\n",
    "            print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))\n",
    "        \n",
    "    return model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(**kwargs):\n",
    "    data0 = torch.randn(kwargs['samples'], kwargs['input_width'])\n",
    "    \n",
    "    if ('true_dim' in kwargs) and (kwargs['true_dim']<kwargs['input_width']):\n",
    "        data0[:,kwargs['true_dim']:] = 0\n",
    "        data0 = data0 @ special_ortho_group.rvs(kwargs['input_width'])\n",
    "        data0 = data0.float()\n",
    "        \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        data0, batch_size=kwargs['batch_size']\n",
    "    )\n",
    "    \n",
    "    return data0, train_loader\n",
    "\n",
    "def PCA_compare(model, model_loss, data0, **kwargs):\n",
    "    U, s, V = np.linalg.svd(data0, full_matrices=False)\n",
    "\n",
    "    b=np.append(s[:kwargs['hidden_width']], np.zeros(len(s)-kwargs['hidden_width']))\n",
    "    L_opt = np.sum(s**2-b**2)*kwargs['batch_size']/kwargs['samples']\n",
    "\n",
    "    print(\"Model loss = \", model_loss)\n",
    "    print(\"PCA loss = \", L_opt)\n",
    "\n",
    "#     print(\"\\nModel params:\")\n",
    "#     for n, p in model.named_parameters():\n",
    "#         print(n, p)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"model estimate:\\n\", model(data0.to(device)).float())\n",
    "        print(\"\\nPCA estimate:\\n\", U  @ np.diag(b) @ V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear activation implies that AutoEncoder = PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss =  285.1575469970703\n",
      "PCA loss =  284.8278944986494\n",
      "model estimate:\n",
      " tensor([[-1.858, -0.321, -0.645,  0.577, -1.535,  0.040],\n",
      "        [ 0.572,  0.076,  0.465, -0.811, -2.136, -1.342],\n",
      "        [ 0.344,  0.013,  0.112, -0.022,  0.661,  0.223],\n",
      "        ...,\n",
      "        [-0.531,  0.494, -0.481,  0.087, -1.099, -0.776],\n",
      "        [ 0.431,  1.107, -0.412, -0.173, -0.398, -1.186],\n",
      "        [ 0.276,  0.454, -0.212,  0.116,  0.833, -0.003]], device='cuda:0')\n",
      "\n",
      "PCA estimate:\n",
      " [[-1.856 -0.327 -0.656  0.574 -1.538  0.029]\n",
      " [ 0.577  0.062  0.474 -0.816 -2.139 -1.349]\n",
      " [ 0.339  0.018  0.109 -0.018  0.661  0.225]\n",
      " ...\n",
      " [-0.542  0.488 -0.477  0.083 -1.094 -0.775]\n",
      " [ 0.414  1.115 -0.402 -0.181 -0.398 -1.192]\n",
      " [ 0.271  0.46  -0.206  0.113  0.834 -0.001]]\n"
     ]
    }
   ],
   "source": [
    "# hyperparams\n",
    "params = {\n",
    "    # data    \n",
    "    \"input_width\": 6, \n",
    "    \"samples\": 1000,\n",
    "    \n",
    "    # model\n",
    "    \"hidden_width\":3,\n",
    "    \"linear\":True,\n",
    "    \"bias\": False,\n",
    "    \n",
    "    # training\n",
    "    \"lr\": 1e-3,\n",
    "    \"batch_size\": 100,\n",
    "    \"epochs\": 1000\n",
    "}\n",
    "\n",
    "data0, train_loader = gen_data(**params)\n",
    "\n",
    "model = shallow_AE(**params).to(device)\n",
    "opt = optim.SGD(model.parameters(), lr=params['lr'])\n",
    "crit = nn.MSELoss(reduction='sum')\n",
    "\n",
    "model_trained, model_loss = train(model, params[\"epochs\"], train_loader, opt, crit, verbose=False)\n",
    "\n",
    "PCA_compare(model_trained, model_loss, data0, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if the true input dimension is smaller than the width of the network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss =  2.676261122436241e-12\n",
      "PCA loss =  -1.0023780874967085e-06\n",
      "model estimate:\n",
      " tensor([[ 0.635,  0.139, -0.340,  0.093,  1.516,  0.880],\n",
      "        [ 0.009, -0.783, -0.952, -0.064, -0.761, -1.064],\n",
      "        [-0.379,  0.127,  0.457, -0.038, -0.695, -0.237],\n",
      "        ...,\n",
      "        [-0.407,  0.010,  0.338, -0.051, -0.872, -0.428],\n",
      "        [-0.474,  0.603,  1.107, -0.011, -0.428,  0.313],\n",
      "        [ 0.373, -0.814, -1.281, -0.020, -0.002, -0.712]], device='cuda:0')\n",
      "\n",
      "PCA estimate:\n",
      " [[ 0.635  0.139 -0.34   0.093  1.516  0.88 ]\n",
      " [ 0.009 -0.783 -0.952 -0.064 -0.761 -1.064]\n",
      " [-0.379  0.127  0.457 -0.038 -0.695 -0.237]\n",
      " ...\n",
      " [-0.407  0.01   0.338 -0.051 -0.872 -0.428]\n",
      " [-0.474  0.603  1.107 -0.011 -0.428  0.313]\n",
      " [ 0.373 -0.814 -1.281 -0.02  -0.002 -0.712]]\n"
     ]
    }
   ],
   "source": [
    "params['true_dim'] = params['hidden_width']-1\n",
    "\n",
    "data0, train_loader = gen_data(**params)\n",
    "\n",
    "model = shallow_AE(**params).to(device)\n",
    "opt = optim.SGD(model.parameters(), lr=params['lr'])\n",
    "crit = nn.MSELoss(reduction='sum')\n",
    "\n",
    "model_trained, model_loss = train(model, params[\"epochs\"], train_loader, opt, crit, verbose=False)\n",
    "\n",
    "model_loss\n",
    "PCA_compare(model_trained, model_loss, data0, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
