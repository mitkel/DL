{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder\n",
    "Refs: [DL book](https://www.deeplearningbook.org/contents/autoencoders.html); [inspired by](https://gist.github.com/AFAgarap/4f8a8d8edf352271fa06d85ba0361f26).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch       \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture\n",
    "\n",
    "class shallow_AE(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder_layer = nn.Linear(\n",
    "            in_features=kwargs[\"input_width\"], out_features=kwargs[\"hidden_width\"], bias=kwargs[\"bias\"]\n",
    "        )\n",
    "        self.decoder_layer = nn.Linear(\n",
    "            in_features=kwargs[\"hidden_width\"], out_features=kwargs[\"input_width\"], bias=kwargs[\"bias\"]\n",
    "        )\n",
    "        \n",
    "        if 'linear' in kwargs:\n",
    "            self.linear = kwargs['linear']\n",
    "        else:\n",
    "            self.linear = False\n",
    "\n",
    "    def forward(self, features):\n",
    "        activation = self.encoder_layer(features)\n",
    "        if not self.linear:\n",
    "            activation = F.relu(activation)\n",
    "        reconstructed = self.decoder_layer(activation)\n",
    "        return reconstructed\n",
    "    \n",
    "def train(model, epochs, train_loader, optimizer, criterion, verbose=True):\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        for batch_features in train_loader:\n",
    "            batch_features = batch_features.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(batch_features)\n",
    "            train_loss = criterion(outputs, batch_features)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            loss += train_loss.item()\n",
    "\n",
    "        loss = loss / len(train_loader)\n",
    "        if verbose:\n",
    "            print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))\n",
    "        \n",
    "    return model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(**kwargs):\n",
    "    data0 = torch.randn(kwargs['samples'], kwargs['input_width'])\n",
    "    \n",
    "    if ('true_dim' in kwargs) and (kwargs['true_dim']<kwargs['input_width']):\n",
    "        data0[:,kwargs['true_dim']:] = 0\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        data0, batch_size=kwargs['batch_size']\n",
    "    )\n",
    "    \n",
    "    return data0, train_loader\n",
    "\n",
    "def PCA_compare(model, model_loss, data0, **kwargs):\n",
    "    U, s, V = np.linalg.svd(data0, full_matrices=False)\n",
    "\n",
    "    b=np.append(s[:kwargs['hidden_width']], np.zeros(len(s)-kwargs['hidden_width']))\n",
    "    L_opt = np.sum(s**2-b**2)*kwargs['batch_size']/kwargs['samples']\n",
    "\n",
    "    print(\"Model loss = \", model_loss)\n",
    "    print(\"PCA loss = \", L_opt)\n",
    "\n",
    "#     print(\"\\nModel params:\")\n",
    "#     for n, p in model.named_parameters():\n",
    "#         print(n, p)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"model estimate:\\n\", model(data0.to(device)))\n",
    "        print(\"\\nPCA estimate:\\n\", U  @ np.diag(b) @ V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear activation implies that AutoEncoder = PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss =  281.99938049316404\n",
      "PCA loss =  281.73795430352766\n",
      "model estimate:\n",
      " tensor([[ 0.667, -0.504,  0.036,  0.241,  1.405, -0.488],\n",
      "        [ 0.459, -0.625, -0.455,  0.484,  0.280,  1.241],\n",
      "        [-0.457, -0.297,  0.127,  0.056, -0.661,  0.484],\n",
      "        ...,\n",
      "        [-0.768,  0.290,  0.106, -0.209, -1.365,  0.413],\n",
      "        [-0.073,  1.101, -0.041, -0.471, -0.330, -0.773],\n",
      "        [ 1.154,  0.391, -1.056,  0.317,  0.611,  1.133]], device='cuda:0')\n",
      "\n",
      "PCA estimate:\n",
      " [[ 0.676 -0.621  0.124  0.376  1.439 -0.271]\n",
      " [ 0.49  -0.261 -0.137  0.549  0.343  1.187]\n",
      " [-0.446 -0.254  0.296  0.151 -0.628  0.606]\n",
      " ...\n",
      " [-0.773  0.572 -0.03  -0.456 -1.409 -0.023]\n",
      " [-0.094  0.489 -0.237 -0.324 -0.35  -0.335]\n",
      " [ 1.166  0.374 -0.829  0.501  0.659  1.385]]\n"
     ]
    }
   ],
   "source": [
    "# hyperparams\n",
    "params = {\n",
    "    # data    \n",
    "    \"input_width\": 6, \n",
    "    \"samples\": 1000,\n",
    "    \n",
    "    # model\n",
    "    \"hidden_width\":3,\n",
    "    \"linear\":True,\n",
    "    \"bias\": False,\n",
    "    \n",
    "    # training\n",
    "    \"lr\": 1e-3,\n",
    "    \"batch_size\": 100,\n",
    "    \"epochs\": 1000\n",
    "}\n",
    "\n",
    "data0, train_loader = gen_data(**params)\n",
    "\n",
    "model = shallow_AE(**params).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "crit = nn.MSELoss(reduction='sum')\n",
    "\n",
    "model_trained, model_loss = train(model, params[\"epochs\"], train_loader, opt, crit, verbose=False)\n",
    "\n",
    "PCA_compare(model_trained, model_loss, data0, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if the real input dimension is smaller than the width of the network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss =  3.122950270779967e-12\n",
      "PCA loss =  -4.867875395575538e-06\n",
      "model estimate:\n",
      " tensor([[     0.752,      1.050,     -0.000,      0.000,      0.000,      0.000],\n",
      "        [    -0.059,     -1.274,     -0.000,     -0.000,     -0.000,     -0.000],\n",
      "        [     0.431,      1.165,      0.000,     -0.000,      0.000,      0.000],\n",
      "        ...,\n",
      "        [     1.770,      0.934,     -0.000,      0.000,     -0.000,      0.000],\n",
      "        [    -0.848,     -0.899,     -0.000,      0.000,     -0.000,     -0.000],\n",
      "        [    -0.102,     -0.249,     -0.000,      0.000,     -0.000,     -0.000]],\n",
      "       device='cuda:0')\n",
      "\n",
      "PCA estimate:\n",
      " [[ 0.752  1.05   0.     0.     0.     0.   ]\n",
      " [-0.059 -1.274  0.     0.     0.     0.   ]\n",
      " [ 0.431  1.165  0.     0.     0.     0.   ]\n",
      " ...\n",
      " [ 1.77   0.934  0.     0.     0.     0.   ]\n",
      " [-0.848 -0.899  0.     0.     0.     0.   ]\n",
      " [-0.102 -0.249  0.     0.     0.     0.   ]]\n"
     ]
    }
   ],
   "source": [
    "params['true_dim'] = params['hidden_width']-1\n",
    "\n",
    "data0, train_loader = gen_data(**params)\n",
    "\n",
    "model = shallow_AE(**params).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "crit = nn.MSELoss(reduction='sum')\n",
    "\n",
    "model_trained, model_loss = train(model, params[\"epochs\"], train_loader, opt, crit, verbose=False)\n",
    "\n",
    "model_loss\n",
    "PCA_compare(model_trained, model_loss, data0, **params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
