{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder\n",
    "Refs: [DL book](https://www.deeplearningbook.org/contents/autoencoders.html); [inspired by](https://gist.github.com/AFAgarap/4f8a8d8edf352271fa06d85ba0361f26).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch       \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "torch.set_printoptions(precision=3, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture\n",
    "\n",
    "class shallow_AE(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder_layer = nn.Linear(\n",
    "            in_features=kwargs[\"input_width\"], out_features=kwargs[\"hidden_width\"], bias=kwargs[\"bias\"]\n",
    "        )\n",
    "        self.decoder_layer = nn.Linear(\n",
    "            in_features=kwargs[\"hidden_width\"], out_features=kwargs[\"input_width\"], bias=kwargs[\"bias\"]\n",
    "        )\n",
    "        \n",
    "        if 'linear' in kwargs:\n",
    "            self.linear = kwargs['linear']\n",
    "        else:\n",
    "            self.linear = False\n",
    "\n",
    "    def forward(self, features):\n",
    "        activation = self.encoder_layer(features)\n",
    "        if not self.linear:\n",
    "            activation = F.relu(activation)\n",
    "        reconstructed = self.decoder_layer(activation)\n",
    "        return reconstructed\n",
    "    \n",
    "def train(model, epochs, train_loader, optimizer, criterion, verbose=True):\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        for batch_features in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(batch_features)\n",
    "            train_loss = criterion(outputs, batch_features)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            loss += train_loss.item()\n",
    "\n",
    "        loss = loss / len(train_loader)\n",
    "        if verbose:\n",
    "            print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))\n",
    "        \n",
    "    return model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(**kwargs):\n",
    "    data0 = torch.randn(kwargs['samples'], kwargs['input_width'])\n",
    "    \n",
    "    if ('true_dim' in kwargs) and (kwargs['true_dim']<kwargs['input_width']):\n",
    "        data0[:,kwargs['true_dim']:] = 0\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        data0, batch_size=kwargs['batch_size']\n",
    "    )\n",
    "    \n",
    "    return data0, train_loader\n",
    "\n",
    "def PCA_compare(model, model_loss, data0, **kwargs):\n",
    "    U, s, V = np.linalg.svd(data0, full_matrices=False)\n",
    "\n",
    "    b=np.append(s[:kwargs['hidden_width']], np.zeros(len(s)-kwargs['hidden_width']))\n",
    "    L_opt = np.sum(s**2-b**2)*kwargs['batch_size']/kwargs['samples']\n",
    "\n",
    "    print(\"Model loss = \", model_loss)\n",
    "    print(\"Optimal loss = \", L_opt)\n",
    "\n",
    "    print(\"\\nModel params:\")\n",
    "    for n, p in model.named_parameters():\n",
    "        print(n, p)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"\\nPCA estimate:\\n\", U  @ np.diag(b) @ V)\n",
    "        print(\"model estimate:\\n\", model(data0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear activation implies that AutoEncoder = PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss =  283.50923614501954\n",
      "Optimal loss =  283.49227618437436\n",
      "\n",
      "Model params:\n",
      "encoder_layer.weight Parameter containing:\n",
      "tensor([[-0.342,  0.295, -0.481,  0.071, -0.573, -0.297],\n",
      "        [-0.139, -0.853, -0.300,  0.260,  0.437,  0.280],\n",
      "        [ 0.089, -0.203, -0.231, -0.459,  0.053, -0.352]], requires_grad=True)\n",
      "decoder_layer.weight Parameter containing:\n",
      "tensor([[-0.555, -0.305,  0.306],\n",
      "        [ 0.072, -0.691, -0.416],\n",
      "        [-0.744, -0.482, -0.380],\n",
      "        [ 0.321,  0.357, -1.119],\n",
      "        [-0.608,  0.172,  0.193],\n",
      "        [-0.203,  0.197, -0.788]], requires_grad=True)\n",
      "\n",
      "PCA estimate:\n",
      " [[ 0.299 -1.01  -0.098 -0.488  0.785 -0.047]\n",
      " [ 0.143  0.419  0.478  0.142 -0.017  0.208]\n",
      " [-0.408 -0.633 -0.9    0.012 -0.124 -0.262]\n",
      " ...\n",
      " [ 0.554 -0.704  0.477 -0.444  0.936  0.184]\n",
      " [ 0.393  1.013  0.68  -0.424 -0.281 -0.238]\n",
      " [ 0.062 -0.156  0.825  1.042  0.575  1.15 ]]\n",
      "model estimate:\n",
      " tensor([[ 0.300, -1.010, -0.098, -0.488,  0.786, -0.047],\n",
      "        [ 0.143,  0.419,  0.478,  0.142, -0.017,  0.208],\n",
      "        [-0.407, -0.633, -0.901,  0.011, -0.124, -0.262],\n",
      "        ...,\n",
      "        [ 0.554, -0.704,  0.477, -0.443,  0.937,  0.185],\n",
      "        [ 0.393,  1.013,  0.680, -0.425, -0.281, -0.238],\n",
      "        [ 0.062, -0.155,  0.825,  1.043,  0.575,  1.150]])\n"
     ]
    }
   ],
   "source": [
    "# hyperparams\n",
    "params = {\n",
    "    # data    \n",
    "    \"input_width\": 6, \n",
    "    \"samples\": 1000,\n",
    "    \n",
    "    # model\n",
    "    \"hidden_width\":3,\n",
    "    \"linear\":True,\n",
    "    \"bias\": False,\n",
    "    \n",
    "    # training\n",
    "    \"lr\": 1e-3,\n",
    "    \"batch_size\": 100,\n",
    "    \"epochs\": 1000\n",
    "}\n",
    "\n",
    "data0, train_loader = gen_data(**params)\n",
    "\n",
    "model = shallow_AE(**params)\n",
    "opt = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "crit = nn.MSELoss(reduction='sum')\n",
    "\n",
    "model_trained, model_loss = train(model, params[\"epochs\"], train_loader, opt, crit, verbose=False)\n",
    "\n",
    "PCA_compare(model_trained, model_loss, data0, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if the real input dimension is smaller than the width of the network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss =  4.842910922980836e-10\n",
      "Optimal loss =  -6.294295963016338e-06\n",
      "\n",
      "Model params:\n",
      "encoder_layer.weight Parameter containing:\n",
      "tensor([[-0.572, -0.288, -0.190, -0.391,  0.058,  0.131],\n",
      "        [ 0.262, -0.697, -0.215, -0.190, -0.282,  0.402],\n",
      "        [-0.625,  0.285, -0.233, -0.345,  0.034,  0.320]], requires_grad=True)\n",
      "decoder_layer.weight Parameter containing:\n",
      "tensor([[-1.099,  0.255, -0.488],\n",
      "        [-0.867, -0.908,  0.414],\n",
      "        [ 0.027, -0.025, -0.035],\n",
      "        [-0.207,  0.196,  0.272],\n",
      "        [-0.078,  0.074,  0.102],\n",
      "        [ 0.216, -0.205, -0.283]], requires_grad=True)\n",
      "\n",
      "PCA estimate:\n",
      " [[-0.79   1.679  0.     0.     0.     0.   ]\n",
      " [-1.279 -1.373  0.     0.     0.     0.   ]\n",
      " [ 0.49  -1.433  0.     0.     0.     0.   ]\n",
      " ...\n",
      " [ 1.078  0.092  0.     0.     0.     0.   ]\n",
      " [ 1.672 -1.244  0.     0.     0.     0.   ]\n",
      " [ 0.141  0.698  0.     0.     0.     0.   ]]\n",
      "model estimate:\n",
      " tensor([[    -0.790,      1.679,      0.000,      0.000,      0.000,      0.000],\n",
      "        [    -1.279,     -1.373,      0.000,     -0.000,     -0.000,     -0.000],\n",
      "        [     0.490,     -1.433,     -0.000,     -0.000,     -0.000,     -0.000],\n",
      "        ...,\n",
      "        [     1.078,      0.092,      0.000,     -0.000,     -0.000,      0.000],\n",
      "        [     1.672,     -1.244,      0.000,     -0.000,     -0.000,      0.000],\n",
      "        [     0.141,      0.698,     -0.000,      0.000,      0.000,      0.000]])\n"
     ]
    }
   ],
   "source": [
    "params['true_dim'] = params['hidden_width']-1\n",
    "\n",
    "data0, train_loader = gen_data(**params)\n",
    "\n",
    "model = shallow_AE(**params)\n",
    "opt = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "crit = nn.MSELoss(reduction='sum')\n",
    "\n",
    "model_trained, model_loss = train(model, params[\"epochs\"], train_loader, opt, crit, verbose=False)\n",
    "\n",
    "PCA_compare(model_trained, model_loss, data0, **params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
